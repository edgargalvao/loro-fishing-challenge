# üêü Loro Fishing Challenge - Sistema de Perguntas e Respostas

Este reposit√≥rio implementa um sistema leve de **perguntas e respostas (Q&A)** para o cat√°logo de produtos da fict√≠cia empresa **Loro Pesca**. Ele utiliza embeddings de linguagem e busca por similaridade para encontrar, entre os documentos, a resposta mais relevante a uma pergunta do usu√°rio.

---

## Vis√£o Geral

- Carrega dados tabulares (`CSV`) com produtos e suas especifica√ß√µes t√©cnicas.
- Usa `SentenceTransformer` para gerar embeddings sem√¢nticos.
- Utiliza `KNN` com dist√¢ncia cosseno para buscar documentos similares.
- Permite responder perguntas com base no cat√°logo e nas especifica√ß√µes t√©cnicas.

---
## Decis√µes de Arquitetura
### Cria√ß√£o de documentos com merge por substring
- Juntar `'loro_pesca_catalog.csv'` com `'loro_pesca_techinical_docs.csv'` via substring entre `'product_name'` e `'product_group'`.
- Heur√≠stica simples e eficaz para associa√ß√£o entre produtos e especifica√ß√µes.

### `'all-MiniLM-L6-v2'` da `sentence-transformers`
- Modelo leve, r√°pido e eficiente para gera√ß√£o de embeddings sem a necessidade de GPUs.
- Foi considerado modelos como Ollama, por√©m n√£o consegui gerar uma key da OpenAI.

### `'sklearn.neighbors-NearestNeighbors'` com m√©trica cosseno
- Implementa√ß√£o simples e eficaz para projetos pequenos com poucos documentos
- 
### Resposta com LLM
- Passa a pergunta e o documento recuperado para o modelo `'deepset/roberta-base-squad2'` via o pipeline da `'Hugging Face'`.
- Retorna a resposta extra√≠da do trecho do documento.


### Separa√ß√£o modular por responsabilidade
- Dividir sistema em m√≥dulos (`'data_loader'`,`'embedder'`,`'retriever'`,`'qa_engine'` e `'app.py'`)
### Interface Streamlit
- Facilitar uso

## Instala√ß√£o

```bash
git clone https://github.com/edgargalvao/loro-fishing-challenge.git
cd loro-fishing-challenge
pip install -r requirements.txt
```

---

## Estrutura

```
loro-fishing-challenge/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     		# Carregamento e jun√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ embedder.py        		# Modelo e gera√ß√£o de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py       		# Busca de documentos por similaridade
‚îÇ   ‚îî‚îÄ‚îÄ qa_engine.py       		# Classe principal do sistema Q&A
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ loro_pesca_catalog.csv		# Produtos, pre√ßos e disponibiliade	
‚îÇ   ‚îî‚îÄ‚îÄ loro_pesca_technical_docs.csv	# Produtos e detalhes t√©cnicos
‚îî‚îÄ‚îÄ app.py				# Interface Streamlit

```

---

## Documenta√ß√£o dos M√≥dulos

### `data_loader.py`

```python
load_data(product_path, specs_path)
```
- L√™ os CSVs dos produtos e especifica√ß√µes.

```python
merge_data(products, specs)
```
- Cria documentos combinando o nome, c√≥digo, pre√ßo, disponibilidade e especifica√ß√µes t√©cnicas.

---

### `embedder.py`

```python
get_model()
```
- Carrega o modelo `'all-MiniLM-L6-v2'` da `sentence-transformers`.

```python
embed_texts(texts, model)
```
- Converte textos em vetores de embeddings.

---

### `retriever.py`

```python
Retriever(embeddings, texts)
```
- Inicializa a busca com KNN e dist√¢ncia cosseno.

```python
query(embedding)
```
- Retorna o documento mais similar ao embedding da pergunta.

---

### `qa_engine.py`

```python
QASystem(product_path, specs_path)
```
- Carrega os dados, cria os documentos, gera embeddings e indexa tudo.

```python
answer(question)
```
- Retorna a resposta mais relevante com base na pergunta do usu√°rio.

---

## Exemplo de Uso

```bash
streamlit run app.py
```

---

## Modelo Utilizado

- [`sentence-transformers/all-MiniLM-L6-v2`](https://www.sbert.net/docs/pretrained_models.html)
  - Leve, eficiente e ideal para tarefas de busca sem√¢ntica.

---
## Considera√ß√µes finais
- O sistema funciona bem para palavras chaves como: "Dispon√≠vel", "Indispon√≠vel", etc. Pois ele interpreta as palvras dadas no dataset.
- O sistema n√£o funiciona muito bem para palavras subjetivas como: "Mais caro", "Mais barato".
- A maior dificuldade foi em tentar encontrar o modelo ideal para o projeto. Em Sentence Transformers temos varios modelos, mas ap√≥s experimentos com modelos muito maiores, com desempenho n√£o muito superior.
- Outra grande dificuldade foi tentar implementar com OpenAI. N√£o fui capaz de rodar Ollama, devido a necessidade da chave de acesso.
---
